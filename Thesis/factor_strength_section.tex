\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{mathptmx}
\usepackage{setspace}
\usepackage{amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage[margin=2.5cm]{geometry}
\usepackage[title]{appendix}
\usepackage{bm}
\usepackage{tcolorbox}
\usepackage{apacite}
\onehalfspacing
\usepackage{lineno}
\linenumbers
\usepackage{diagbox}

\DeclareMathOperator*{\argmin}{arg\,min}
\newtheorem{experiment}{Experiment}



\usepackage{fontspec}
\setmainfont{Times New Roman}
\addtolength{\jot}{0.5em}
\linespread{1.5}




		
		\begin{document}
\section{Factor Strength}\label{strength}
The concept of factor strength employed by this project comes from \citeA{Bailey2020}, and it was first introduced by \citeA{Bailey2016}.
They defined the strength of factor from prospect of the cross-section dependences of large panel and connect it to the pervasiveness of the factor, which is captured by the factor loadings.
%The method present in the initial paper focusing the estimation from unobserved factor.
In a latter paper, \citeA{BKP2019} extended the method by loosen some restrictions, and proved that their estimation can also be applied on the residuals or regression result.
Thereafter, they focusing on the case of observed factors, and proposed the method we employed in this project \cite{Bailey2020}.

		\subsection{Definition}\label{definiton}

Consider the following multi-factor model for n different cross-section units and T observations with k  factors.

\[  x_{it} = a_{t}+  \sum_{j=1}^{k}\beta_{ij}f_{jt} + \varepsilon_{it} \tag{1}\label{definition_model} \]
In the left-hand side, we have $x_{it}$ denotes the cross-section unit i at time t, where $i = 1, 2,3, \cdots, n$ and $t = 1,2,3, \cdots T$.  
In the other hand, $a_{i}$ is the constant term.
$f_{jt}$ of $j = 1, 2, 3\cdots k$ is factors included in the model, and $\beta_{ij}$ is the corresponding factor loading.
$\varepsilon_{it}$ is the stochastic error term.

The factor strength is relates to how many non-zero loadings correspond to a factor.
More precisely, for a factor $f_{jt}$ with n different factor loading $\beta_{j}$, we assume that:
\begin{align*}
|\beta_{j}| &> 0\quad i = 1, 2,  \dots, [n^{\alpha_j}]\\
|\beta_{j}| &= 0 \quad i = [n^{\alpha_j}] + 1, [n^{\alpha_j}] +2 ,\dots, n
\end{align*}
The $\alpha_j$ represents strength of factor $f_{jt}$ and $\alpha_j \in [0,1]$.
If factor has strength $\alpha_j$, we will assume that the first $[n^{\alpha_j}]$ loadings are all different from zero, and here $[\cdot] $  is defined as integral operator, which will only take the integral part of inside value.% which indicates that those factors can capture the dynamic behind the cross-section unit effectively.
The rest $n - [n^{\alpha_j}]$ terms are all equal to zero. % which means the factors can not provides any information of interest of  those $n - [n^\alpha_j]$  units.
Assume for a factor which has strength $\alpha = 1$, the factor's loadings will be non-zero for all cross-section units.
We will refer such factor as strong factor.
And if we have factor strength $\alpha = 0$, it means that the factor has all factor loadings equal to zero, and we will describe such factor as weak factor \cite{Bailey2016}.
For any factor with strength in [0.5, 1], we will refer such factor as semi-strong factor.
In general term, the more non-zero loading a factor has, the stronger the factor's strength is. 

	\subsection{Estimation}\label{estimation}
To estimate the strength $\alpha_j$, \citeA{Bailey2020} provides following estimation.

To begin with, we consider a single-factor model with only factor named $f_t$. 
 $\beta_{i}$ is the factor loading of unit i.
$v_{it}$ is the stochastic error term.

\[  x_{it} = a_{i} +  \beta_{i}f_{t} + v_{it} \tag{2} \label{estimation_model}\]

Assume we have n different units and T observations for each unit: $i = 1, 2, 3, \cdots, n$ and $t = 1,2,3, \cdots T$.
Running the OLS regression for each $i = 1,2,3\cdots, n$, we obtain:
\[   x_{it} = \hat{a}_{iT} +  \hat{\beta}_{iT}f_{t} + \hat{v}_{it}  \]

For every factor loading $\hat{\beta}_{iT}$, we can examining their significance by constructing a t-test.
The t-test statistic will be $t_{iT} = \frac{\hat{\beta}_{iT} - 0}{\hat{\sigma}_{iT}}$.  
Then the test statistic for the corresponding $\hat{\beta}_i$ will be:

\[t_{i T}=\frac{\left(\mathbf{f}^{\prime} \mathbf{M}_{\tau} \mathbf{f}\right)^{1 / 2} \hat{\beta}_{i T}}{\hat{\sigma}_{i T}}=\frac{\left(\mathbf{f}^{\prime} \mathbf{M}_{\tau} \mathbf{f}\right)^{-1 / 2}\left(\mathbf{f}^{\prime} \mathbf{M}_{\tau} \mathbf{x}_{i}\right)}{\hat{\sigma}_{i T}} \tag{3} \label{test_statistic} \]
Here, the $\mathbf{M}_{\tau} = \mathbf{I}_T - T^{-1}\mathbf{\tau}\mathbf{\tau^\prime}$, and the $\mathbf{\tau}$ is a $T\times 1$ vector with every elements equals to 1.
$\mathbf{f}$ and $\mathbf{x_i}$ are two vectors with: $\mathbf{f} = (f_1, f_2 \cdots, f_T)^{\prime}$   $\mathbf{x_i} = (x_{i1}, x_{i2}, \cdots, x_{iT})$.
The denominator $\hat{\sigma}_{iT} = \frac{\sum_{i=1}^{T} \hat{v}^2_{it} }{T}$.

Using this test statistic, we can then define an indicator function as: $\ell_{i,n} := {\bf1}[|\beta_i|>0]$.
If the factor loading is none-zero, $\ell_{i,n} = 1$.
In practice, we use the $\hat{\ell}_{i,nT} = := {\bf1}[|t_{it}|>c_p(n)]$
Here, if the t-statistic $t_{iT}$ is greater than critical value $c_p(n)$,  $\hat{\ell}_{i,n} = 1$, otherwise $\hat{\ell}_{i,n} = 0$
In other word, we are counting how many $\hat{\beta}_{iT}$ are significant.
With the indicator function, we then defined $\hat{\pi}_{nT}$ as the fraction of significant factor loading amount to the total factor loadings:

\[  \hat{\pi}_{nT} = \frac{\sum_{i=1}^n \hat{\ell}_{i,nT}}{n} \tag{4} \label{pi_function} \]


In term of the critical value $c_p(n)$, rather than use the traditional critical value from student-t distribution $\Phi^{-1}(1-\frac{P}{2})$, we use:

\[   c_p(n) = \Phi^{-1}(1 - \frac{p}{2n^\delta})   \tag{5} \label{critical_value_function} \]

Suggested by \citeA{Bailey2019}, here, $\Phi^{-1}(\cdot)$ is the inverse cumulative distribution function of a standard normal distribution, P is the size of the test, and $\delta$ is a non-negative value represent the critical value exponent. 
This adjusted critical value, adopt helps to tackle the problem of multiple-test.

After obtain the $\hat{\pi}_{nT}$, we can use the following formula provided by \citeA{Bailey2020} to estimate our strength indicator $\alpha_j$:
\[ \hat{\alpha} = \begin{cases}
1+\frac{\ln(\hat{\pi}_{nT})}{\ln n} & \text{if}\; \hat{\pi}_{nT} > 0,\\
0, & \text{if}\; \hat{\pi}_{nT} = 0.
	\end{cases} \tag{6} \label{estimation_method} \]

Whenever we have $\hat{\pi}_{nT}$, the estimated $\hat{\alpha}$ will be equal to zero. 
From the estimation, we can find out that $\hat{\alpha} \in [0,1]$

\subsection{Estimation Under Multi-Factor Setting}

This estimation can also be extended into a multi-factor set up.
Consider the following multi-factor model:
\[x_{it} = a_i +\sum_{j = 1}^k\beta_{ij}f_{jt} +v_{it} = a_i + \mathbf{\beta^{\prime}_{i}f_{t}} +v_{it} \]

In this set up, we have $i = 1, 2, \cdots, n$ units, $t = 1, 2, \cdots, T$ time observations, and specially, $j = 1, 2,\cdots, k$ different factors.
Here $\mathbf{\beta}_{i} = (\beta_{i1}, \beta_{i2}, \cdots, \beta_{ij})^{\prime} $ and $\mathbf{f}_t = (f_{1t}, f_{2t}\cdots, f_{jt})$.
We employed the same strategy as above, after running OLS and obtain the:

\[ x_{it} =\hat{a}_{iT} + \mathbf{\hat{\beta}_{ij}}\mathbf{f}_{jt} + \hat{v}_{it}    \]
To conduct the significant test, we calculates the t-statistic: $t_{ijT} = \frac{\hat{\beta}_{ijT}-0}{\hat{\sigma}_{ijT}}$. Empirically, the test statistic can be calculated using:
\[ t_{i j T}=\frac{\left(\mathbf{f}_{j \circ}^{\prime} \mathbf{M}_{F_{-j}} \mathbf{f}_{j \circ}\right)^{-1 / 2}\left(\mathbf{f}_{j \circ}^{\prime} \mathbf{M}_{F_{-j}} \mathbf{x}_{i}\right)}{\hat{\sigma}_{i T}} \]

Here, $\mathbf{f}_{j \circ}=\left(f_{j 1}, f_{j 2}, \ldots, f_{j T}\right)^{\prime}, \mathbf{x}_{i}=\left(x_{i 1}, x_{i 2}, \ldots, x_{i T}\right)^{\prime}, \mathbf{M}_{F_{-j}}=\mathbf{I}-\mathbf{F}_{-j}\left(\mathbf{F}_{-j}^{\prime} \mathbf{F}_{-j}\right)^{-1} \mathbf{F}_{-j}^{\prime}$, and $\mathbf{F}_{-j}=\left(\mathbf{f}_{1 \circ}, \ldots, \mathbf{f}_{j-1 \circ}, \mathbf{f}_{j+1 \circ}, \ldots, \mathbf{f}_{m \circ}\right)^{\prime}$
For the denominator's $\hat{\sigma}_{iT}$, it was from $\hat{\sigma}_{i T}^{2}=T^{-1} \sum_{t=1}^{T} \hat{u}_{i t}^{2}$, the $\hat{u}_{it}$ is the residuals of the model.
Then, we can use the same critical value from (\ref{critical_value_function}).
Obtaining the correspond ratio $\hat{\pi}_{nTj}$  from (\ref{pi_function}), and after that use the function:
\begin{equation*}
\hat{\alpha}_{j}=\left\{\begin{array}{l}
1+\frac{\ln \hat{\pi}_{n T, j}}{\ln n}, \text { if } \hat{\pi}_{n T, j}>0 \\
0, \text { if } \hat{\pi}_{n T, j}=0
\end{array}\right.
\end{equation*}
to estimates the factor loading.

%+==================+==================+==================+===============&
%+==================+==================+==================+===============&

	\section{Monte Carlo Design}\label{MC}
	\subsection{Design}
In order to study the finite sample property of factor strength $\hat{\alpha}_j$, we designed a Monte Carlo simulation.
Through the simulation, we compare the property of the factor strength in different settings.
We set up the experiments to reflect the CAPM model and it's extension.
Consider the following data generating process (DGP):

	\[ r_{it} - r_{ft} = q_1({r_{mt}} - r_f) + q_2( \sum_{j=1}^k\beta_{ij}f_{jt}) +\epsilon_{it} \]


In the simulation, we consider a dataset has $i = 1, 2,\dots, n$ different cross-section units, with $t= 1, 2,\dots, T$ different observations. 
$r_{it}$ is the unit's return, and $r_{ft}$ represent the risk free rate at time t, therefore, the left hand side term $r_{it} - r_{ft}$ is the excess return of the unit i.
For simplicity, we define $x_{it} := r_{it}- r_{ft}$.
$f_{jt}$ represents different risk factors, and the corresponding  $\beta_{ij}$ are the factor loadings.
We use $r_{mt} - r_{ft}$ to denotes the market factor, and here $r_{mt}$ is the average market return.
Also, we use the term $f_{mt} := r_{mt} - r_{ft}$ to denotes the market factor.
We expect the market factor will has strength equals to one all the time, so we consider the market factor has strength $\alpha_m = 1$.
$\varepsilon_{it}$ is the stochastic error term.
Therefore, the simulation model can be simplified as:

\[ x_{it} = q_1(f_{mt}) + q_2( \sum_{j=1}^k\beta_{ij}f_{jt}) +\epsilon_{it}  \]

$q_1(\cdot)$ and $q_2(\cdot)$ are two different functions represent the unknown mechanism of market factor and other risk factors in pricing asset risk.
In the classical CAPM model and it's multi-factor extensions, for example the three factor model introduced by \citeA{Fama1992}, both $q_1$ and $q_2$ are linear.

 For each factor, we assume they follow a multinomial distribution with mean zero and a $k\times k$ variance-covariance matrix $\Sigma$. 
\begin{align*}
\mathbf{f_t} = \begin{pmatrix}
f_{i,t}\\f_{2,t}\\\vdots\\f_{k,t}
\end{pmatrix} \sim MVN(\mathbf{0}, \Sigma) \quad
 \Sigma := 
\begin{pmatrix}
\sigma^2_{f_1}, & \rho_{12}\sigma_{f1}\sigma_{f2} &\cdots  & \rho_{1k}\sigma_{f1}\sigma_{fk}\\
\rho_{12}\sigma_{f2}\sigma_{f1}, & \sigma^2_{f2} &\cdots  & \rho_{2k}\sigma_{f2}\sigma_{fk}\\
\vdots & \vdots & \ddots & \vdots \\
\rho_{1k}\sigma_{fk}\sigma_{f1}, & \rho_{k2}\sigma_{fk}\sigma_{f2} &\cdots  & \sigma^2_{fk}\\
\end{pmatrix}
\end{align*}
The diagonal of matrix $\Sigma$ indicates the variance of each factor, and the rest represent the covariance among all $k$ factors.


	\subsection{Experiment Setting}\label{exp_set}



%\subsection{Baseline Experiment}\label{base}
Follow the general model above, we assume both $q_1(\cdot)$ and $q_2(\cdot)$ are linear function:
\begin{align*}
q_1({f_{mt}}) &= a_{i} +\beta_{im} f_{mt}\\
q_2(\sum_{j = 1}^{k}\beta_{ij}f_{jt}) &=\sum_{j = 1}^{k}\beta_{ij}f_{jt}
\end{align*}
To start the simulation, we consider a two factor model:
\[    x_{it} = a_{i} + \beta_{i1}f_{1t} + \beta_{i2}f_{2t}+\epsilon_{it} \tag{7} \label{two_factor}   \]
%Therefore, if we include the market factor with other risk factors together, the model can be simplified as:
%	\[   x_{it} = a_{it} + \sum_{j = 1}^{k+1}  \beta_{ij}f_{jt} +\epsilon_{it}  \tag{6} \label{simplified_multi}  \x]
%And in this first baseline experiment, we will  use the single factor model as:
%\[  x_{it} = a_{it} +  \beta_{i1}f_{1t} +\epsilon_{it} \tag{7} \label{singlefactor}  \]
%Through the simulations, we will control the underlying true strength of factor 
The constant term $a_{i}$ is generate from a uniform distribution, $a_{it} \sim \mathnormal{U}[-0.5,0.5]$.
For the factor loading $\beta_{i1}$ and $\beta_{i2}$, we first use a uniform distribution $IIDU(\mu_{\beta} - 0.2, \mu_{\beta}+0.2)$ to produce the values.
Here we set $\mu_{beta}=0.71$ to make sure every generated loading value is sufficiently larger than 0.
Then we randomly assign $n - [n^{\alpha_{1}}]$ and $n - [n^{\alpha_{2}}]$ factor loadings as zero.
$\alpha_1$ and $\alpha_2$ are the true factor strength of $f_1$ and $f_2$. 
In this simulation, we will start the factor strength from 0.7 and increase it gradually till unity with pace 0.05, say $(\alpha_{1}, \alpha_{2}) = \{0.7, 0.75,0.8,\cdots,1\}$.
 $[\cdot]$ is the integer operator defined at section (\ref{estimation}).
This step reflects the fact that only $[n^\alpha]$ factor loadings are non-zero.
In terms of the factors, they comes from a multinomial distribution $MVN(\mathbf{0}, \Sigma) $, as we discuss before.

Currently, we consider three different experiments set up:

\begin{experiment}[single factor, normal error, no correlation]
Set $\beta_{i2}$ from (\ref{two_factor}) as 0, the error term $\varepsilon_{it}$ and the factor $f_{1t}$ are both standard normal.
\end{experiment}

\begin{experiment}[two factors, normal error, no correlation]
Both $\beta_{i1}$ and $\beta_{i2}$ are non-zero. Error term and both factors are standard normal. The correlation $\rho_{12}$ between $f_{1t}$ and$f_{2t}$ is zero. 
The factor strength for the first factor $\alpha_1 = 1$ all the time, and $\alpha_2$ various.
\end{experiment}

\begin{experiment}[two factors, normal error, weak correlation]
Both $\beta_{i1}$ and $\beta_{i2}$ are non-zero. Error term  and both factors are standard normal. The correlation $\rho_{12}$ between $f_{1t}$ and$f_{2t}$ is 0.3.
The factor strength for the first factor $\alpha_1 = 1$ all the time, and $\alpha_2$ various.
\end{experiment}

The factor strength in each experiment is estimated using the method discussed in section (\ref{estimation}), the size of significant test is $p = 0.05$, and the critical value exponent $\sigma$ has been set as 0.5.
For each of the experiment, we calculate the bias, the RMSE and the size of the test to justify the estimation performances.
The bias is calculated as the difference between the true factor strength $\alpha$ and the estimate factor strength $\hat{\alpha}$.
The Root Square Mean Error (RMSE) comes from:
\[ RMSE =[\frac{1}{R}\sum_{r=1}^{R}(bias_r)^2 ]^{1/2}\]
Where the R represent the total replicate times.
The size of the test is under the hypothesis that $H_0: \hat{\alpha_j} = \alpha_j,\;j =1, 2$ against the alternative hypothesis $H_1:\hat{\alpha_j} \neq \alpha_j,\; j=1,2$.
Here we employed the following test statistic from \citeA{Bailey2020}.

	\[  z_{\hat{\alpha_j}:\alpha_j} =\frac{(\ln n)\left(\hat{\alpha_j}-\alpha_{j}\right)-p\left(n-n^{\hat{\alpha_j}}\right) n^{-\delta-\hat{\alpha_j}}}{\left[p\left(n-n^{\hat{\alpha}_j}\right) n^{-\delta-2 \hat{\alpha}_j}\left(1-\frac{p}{n^{\delta}}\right)\right]^{1 / 2}}\quad j=1,2 \tag{8}  \label{z_indicator}\]

Define a indicator function $\mathbf{1}(|z_{\hat{\alpha_j}:\alpha_j} |>c|H_0)$.
For each replication, if this test statistic is greater than the critical value of standard normal distribution: $c = 1.96$, the indicator function will return value 1, and 0 otherwise.
Therefore, we calculate the size of the test base on:
	\[ size = \frac{\sum_{r=1}^{R} \mathbf{1}(|z_{\hat{\alpha_j}:\alpha_j} |>1.96|H_0)}{R} \quad j =1,2 \tag{9}, \label{size_calculator}\]

%Next, we set up the true factor strength $\alpha$.
%Through the whole simulation, we will assign the strength with different value $\alpha = \{0.5, 0.7, 0.9, 1\}$, and since in this baseline design we only contain one factor, the only factor's strength will be selected from the above set. 
%After having the factor strength, we can calculate for each factor, how many loadings should be different from zero.
%From the section (\ref{definiton}), we assume that for any factor with strength $\alpha_j$, the factor is supposed to generate $[n^{\alpha_j}]$ non-zero factor loadings, and $n- [n^{\alpha_j}]$ zero loadings.
%Therefore, we can calculate the $n - [n^{\alpha_j}]$.

%From the previous section, we assume factors will follow a multinomial standard distribution with mean zero and variance $\Sigma$.
%This means that for each factors, they should follow a normal distribution.
%In this baseline design, we only contain one factor, and this factor will generate form standard error distribution.


%For this experiment, we construct the hypothesis test base on the null hypothesis $H_O:\beta_{i1} = 0$ against the alternative hypothesis $H_1:\beta_{i1}\neq0$.
%The  test statistic and critical value are from equation (\ref{test_statistic}) and equation (\ref{critical_value_function}).
%We consider two-sided tests, with size 0.05.
%Therefore, the corresponding critical value for such t-test will be $\delta = 1.96$

%After generate constant term, factor, factor loading, and the error term, we can calculate the simulated asset's return by using the equation (\ref{singlefactor}).
%With the return and factors, we can re-calculate the factors loading and use the estimation method discussed in section \ref{estimation}.



%\subsection{Two factor experiment}
%Follow the similar idea as baseline design, we can easily extend the DGP into multi-factor form. 
%We derive a two-factor model from the model  (\ref{simplified_multi}).
%	\[   x_{it} = a_{it} + \beta_{i1}f_{1t} + \beta_{i2}f_{2t}+\epsilon_{it}  \tag{8}  \]
%Here $\mathbf{f}_t = (f_{1t}, f_{2t})^{\prime}$ are two different factors generate from multivariate normal distribution with mean zero and variance $\Sigma$.
%In this simulation, we assume two factors are independent with each other and both of them have variance equals to one, the variance-covariance matrix $\Sigma$ of factors %$\mathbf{f_t}$ will be:
%\begin{align*}
%\Sigma_{\mathbf{f_t}} := 
%\begin{pmatrix}
%1 &0\\
%0 & 1 \\
%\end{pmatrix}
%\end{align*}
%Besides, for the factor $f_{1t}$, we assign it as the market factor, which indicates that the factor strength $\alpha_1$ will be unit.
%And all factor loading generates from this factor will be different from zero.
%For the rest of the variables, we follow the same procedure as the baseline experiment.

In purpose of Monte Carlo Simulation, we consider the different combinations of T and n with $T = \{120, 240, 360\}$, $n =\{100, 300, 500\} $.
The market factor, if included in the experiment, will have strength $\alpha_m = 1$ all the time, and the strength of the other factor will be $\alpha_{x} = \{0.7, 0.75, 0.8,0.85, \\
0.9,0.95, 1\}$. For every setting, we will replicate 2000 times independently, all the constant and variables will be re-generated for each replication.


 
\subsection{Monte Carlo Discoveries}
We report the results in Table (\ref{exp1_table}) , (\ref{exp2_table}) and (\ref{exp3_table}) in Appendix \ref{simulationtable}.

Table (\ref{exp1_table}) provides the results under the experiment 1.
The estimation method we applied tends to under-estimate the strength slightly most of the time when the true strength is relatively weak under the single factor set up.
The bias is about 0.01 lower when the true underlying factor strength is 0.7.
Such bias, however, vanish quickly while time t, unit amount n, and  $\alpha$ increase.
When we increase the time spam by including more data from the time dimensions, the bias, as well as the RMSE decrease significantly.
Also, when including more cross-section unit n into the simulation, the performance of the estimation improves, showing by the decrease bias and RMSE values.
An impressing result is that, the gap between estimation and true strength will goes to zero when we have $\alpha = 1$, the strongest we can have.
With the strength approaching unity, the both bias and RMSE will converge to zero.
Then we turn our attention to the size of the test.
The size of the test will not variate too much when the strength increases, so as the unit increases,
But we can observe that when observations for each unit increase, in other word, when t increases, the size will shrinkage dramatically.
The size will smaller than the 0.05 threshold after we extend the t to 240, or empirically  speaking, when we included 20 years monthly return data into estimation.
Notice that, from the equation (\ref{z_indicator}), when $\hat{\alpha} = \alpha = 1$, the nominator will becomes zero.
Therefore, the size will collapse into zero in all settings, so we do not report the size for $\hat{\alpha} = \alpha = 1$

For the two factors scenarios, we obtain similar conclusions in both the no correlation setting and weak correlation setting.
The result of no correlation settings is shown in the table (\ref{exp2_table}), and the table (\ref{exp3_table}) shows the result when the correlation between two factors is 0.3.
Same as the single factor results, in most of the time, our estimation method will slightly under estimates the factor strength. 
But we can improve the estimation result by increasing either the observations amount t, or the cross-section units amount n.
We also have the same unbiased estimation when true factor strength is unity under all unit-time combination.
In some cases, even when the factor strength is relatively weak,we can have unbiased estimation if the n and t are big enough. (see table (\ref{exp3_table})).
The results of size of the test in two factors setting are performing similar to the single factor result. 
The size will shrink with the observation amount t increasing, and when we have t grater than 240, the size will be smaller than 0.05 threshold in all situations.

%Same results are found in the two factors experiments.
%Table (\ref{exp2_table}) and Table (\ref{exp3_table}) shows the result of experiment 2 and 3.
%With regard of the correlation $\rho_{12}$ between factors, we found that for either cases the  $\rho{12} = 0$ or $\rho_{12} = 0.3$, the bias and RMSE will decrease gradually till converge to zero when the true strength is approaching unity.

\newpage
\bibliographystyle{apacite}
\bibliography{thesis.bib}

\newpage
\appendix
\input{appendix.tex}


		\end{document}
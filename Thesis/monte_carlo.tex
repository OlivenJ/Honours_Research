\chapter{Monte Carlo Simulation}\label{MC}
	In this chapter, we set up several simple Monte Carlo simulation experiments to study the finite sample properties of factor strength $\hat{\alpha}_j$.
	Through the simulation, we compare the property of the factor strength in different settings.
	
\section{Simulation Design}
The experiments is designed to reflect the CAPM model and its extension.
For simplicity, we first define $x_{it} := r_{it}- rf_{t}$.
$r_{it}$ is the unit's return, and $rf_{t}$ represent the risk-free rate at time t, therefore, the $x_{it}$ is the excess return of unit i at time t.
We use $f_{mt}:=r_{mt} - rf_{t}$ to denote the market factor, and $\beta_{im}$ to denote the market factor loading.
The market factor is defined as the difference between the average market return and the risk free return.
Here $r_{mt}$ is the average market return of hypothetically all assets in the universe.
%Additionally, we set $q_1(\cdot)$ and $q_2(\cdot)$ as two different functions that represent the unknown mechanism of market factor and other risk factors in pricing asset risk.
%In the classical CAPM model and it's multi-factor extensions, for example, the three-factor model introduced by \citeA{Fama1992}, both $q_1$ and $q_2$ are linear.
Now consider the following data generating process (DGP):
	
		\[ x_{it} = \beta_{im}f_{mt} +  \sum_{j=1}^k\beta_{ij}f_{jt} +\epsilon_{it}  \]
	
%	\[ x_{it} = q_1(f_{mt}) + q_2( \sum_{j=1}^k\beta_{ij}f_{jt}) +\epsilon_{it}  \]


In the simulation, we consider a dataset has $i = 1, 2,\dots, n$ different cross-section units, with $t= 1, 2,\dots, T$ different time-series observations. 
Different risk factors are represented by the $f_{jt}$, and the corresponding $\beta_{ij}$ are the factor loadings.
We expect the market factor will have strength equal to one all the time, so we consider the market factor has strength $\alpha_m = 1$, and this will be reflected in the setting.
$\varepsilon_{it}$ is the stochastic error term.

% For each factor, we assume they follow a multivariate normal distribution with mean zero and a $k\times k$ variance-covariance matrix $\Sigma$. 
%\begin{align*}
%\bm{f_t} = \begin{pmatrix}
%f_{i,t}\\f_{2,t}\\\vdots\\f_{k,t}
%\end{pmatrix} \sim MVN(\bm{0}, \Sigma) \quad
 %\Sigma := 
%\begin{pmatrix}
%\sigma^2_{f_1}, & \rho_{12}\sigma_{f1}\sigma_{f2} &\cdots  & \rho_{1k}\sigma_{f1}\sigma_{fk}\\
%\rho_{12}\sigma_{f2}\sigma_{f1}, & \sigma^2_{f2} &\cdots  & \rho_{2k}\sigma_{f2}\sigma_{fk}\\
%\vdots & \vdots & \ddots & \vdots \\
%\rho_{1k}\sigma_{fk}\sigma_{f1}, & \rho_{k2}\sigma_{fk}\sigma_{f2} &\cdots  & \sigma^2_{fk}\\
%\end{pmatrix}
%\end{align*}
%The diagonal of matrix $\Sigma$ indicates the variance of each factor, and the rest represent the covariance among all $k$ factors.


	\section{Experiment Setting}\label{exp_set}
%Follow the general model above, we assume both $q_1(\cdot)$ and $q_2(\cdot)$ are linear function:
%\begin{align*}
%q_1({f_{mt}}) &= a_{i} +\beta_{im} f_{mt}\\
%q_2(\sum_{j = 1}^{k}\beta_{ij}f_{jt}) &=\sum_{j = %1}^{k}\beta_{ij}f_{jt}
%\end{align*}
To start the simulation, we consider a two-factor model:
\[    x_{it} = a_{i} + \beta_{i1}f_{1t} + \beta_{i2}f_{2t}+\epsilon_{it} \tag{8} \label{two_factor}   \]
The constant term $a_{i}$ is generated from a uniform distribution, $a_{it} \sim \mathnormal{U}[-0.5,0.5]$.
For the factor loading $\beta_{i1}$ and $\beta_{i2}$, we first use a uniform distribution $IIDU(\mu_{\beta} - 0.2, \mu_{\beta}+0.2)$ to produce the values.
Here we set $\mu_{\beta}=0.71$ to make sure every generated loading value is sufficiently larger than 0.
Then we randomly assign $n - [n^{\alpha_{1}}]$ and $n - [n^{\alpha_{2}}]$ factor loadings as zero.
$\alpha_1$ and $\alpha_2$ are the true factor strength of $f_1$ and $f_2$. 
In this simulation, we will start the factor strength from 0.7 and increase it with increment 0.05 till unity, say $(\alpha_{1}, \alpha_{2}) = \{0.7, 0.75,0.8,\cdots,1\}$.
 $[\cdot]$ is the integer operator defined at chapter \ref{strength_one_factor_estimation}.
This step reflects the fact that only $[n^{\alpha_1}]$ or $[n^{\alpha_2}]$ factor loadings are non-zero.
In terms of the factors, they come from a multinomial distribution $MVN(\bm{0}, \Sigma) $, 
\begin{align*}
 \begin{pmatrix}
		f_{i,t}\\f_{2,t}
	\end{pmatrix} \sim MVN(\bm{0}, \Sigma) \quad
	\Sigma := 
	\begin{pmatrix}
		\sigma^2_{f_1}, & \rho_{12}\sigma_{f1}\sigma_{f2} \\
		\rho_{12}\sigma_{f2}\sigma_{f1}, & \sigma^2_{f2} \\
	\end{pmatrix}
\end{align*}
The diagonal of matrix $\Sigma$ indicates the variance of each factor, and the rest represent the covariances.

Currently, we consider four different experiments set up:

\begin{experiment}[single factor, normal error, no correlation]
Set $\beta_{i2}$ from (\ref{two_factor}) as 0, the error term $\varepsilon_{it}$ and the factor $f_{1t}$ are both standard normal.
\end{experiment}

\begin{experiment}[two factors, normal error, no correlation]
Both $\beta_{i1}$ and $\beta_{i2}$ are non-zero. Error term and both factors are standard normal. The correlation $\rho_{12}$ between $f_{1t}$ and $f_{2t}$ is zero. 
The factor strength for the first factor $\alpha_1 = 1$ all the time, and $\alpha_2$ varies.
\end{experiment}

\begin{experiment}[two factors, normal error, weak correlation]
Both $\beta_{i1}$ and $\beta_{i2}$ are non-zero. Error term  and both factors are standard normal. The correlation $\rho_{12}$ between $f_{1t}$ and $f_{2t}$ is 0.3.
The factor strength for the first factor $\alpha_1 = 1$ all the time, and $\alpha_2$ varies.
\end{experiment}

\begin{experiment}[two factors, normal error, strong correlation]
	Both $\beta_{i1}$ and $\beta_{i2}$ are non-zero. Error term and both factors are standard normal. The correlation $\rho_{12}$ between $f_{1t}$ and $f_{2t}$ is 0.7.
	The factor strength for the first factor $\alpha_1 = 1$ all the time, and $\alpha_2$ varies.
\end{experiment}

The factor strength in experiment one is estimated using the method discussed in chapter (\ref{strength_one_factor_estimation}), and for the rest of experiments, we use the method from chapter \ref{strength_multi_estimation}.
The size of the significance test is $p = 0.05$, and the critical value exponent $\sigma$ has been set as 0.5.
For each experiment, we calculate the bias, the RMSE and the size of the test to assess the estimation performances.
The bias is calculated as the average of difference between the true factor strength $\alpha$ and the estimated factor strength $\hat{\alpha}$.
\[bias = \frac{1}{R}\sum_{r = 1}^R(\alpha - \hat{\alpha}_r)\]
The Root Square Mean Error (RMSE) comes from:
\[ RMSE =[\frac{1}{R}\sum_{r=1}^{R}(bias_r)^2 ]^{1/2}\]
Where the R represents the total number of replication.
The size of the test is under the hypothesis that $H_0: \hat{\alpha_j} = \alpha_j,\;j =1, 2$ against the alternative hypothesis $H_1:\hat{\alpha_j} \neq \alpha_j,\; j=1,2$.
Here we employed the following test statistic from \citeA{Bailey2020}.

	\[  z_{\hat{\alpha_j}:\alpha_j} =\frac{(\ln n)\left(\hat{\alpha_j}-\alpha_{j}\right)-p\left(n-n^{\hat{\alpha_j}}\right) n^{-\delta-\hat{\alpha_j}}}{\left[p\left(n-n^{\hat{\alpha}_j}\right) n^{-\delta-2 \hat{\alpha}_j}\left(1-\frac{p}{n^{\delta}}\right)\right]^{1 / 2}}\quad j=1,2 \tag{9}  \label{z_indicator}\]

Define a indicator function $\bm{1}(|z_{\hat{\alpha_j}:\alpha_j} |>c|H_0)$.
For each replication, if this test statistic is greater than the critical value of standard normal distribution: $c = 1.96$, the indicator function will return value 1, and 0 otherwise.
Therefore, we calculate the size of the test base on:
	\[ size = \frac{\sum_{r=1}^{R} \bm{1}(|z_{\hat{\alpha_j}:\alpha_j} |>1.96|H_0)}{R} \quad j =1,2 \tag{10}, \label{size_calculator}\]


For this Monte Carlo Simulation, we consider the different combinations of T and n with $T = \{120, 240, 360\}$, $n =\{100, 300, 500\} $.
The market factor is designed to have strength $\alpha_m = 1$ all the time, and the strength of the other factor will be $\alpha_{x} = \{0.7, 0.75, 0.8,0.85, 0.9,0.95, 1\}$. For every setting, we will repeat the experiment 2000 times independently, all the constant and variables will be re-generate for each replication.


 
	\section{Monte Carlo Findings}\label{MC_findings}
We report the results in Table (\ref{table:exp1}), (\ref{table:exp2}), (\ref{table:exp3}), and (\ref{table:exp4}) in Appendix \ref{simulationtable}.

Table (\ref{table:exp1}) provides the results under the experiment 1.
The estimation method we applied tends to over-estimate the strength slightly most of the time when the true strength is relatively weak under the single factor set up.
With the true strength increasing, the bias will turn to negative, represents an under-estimated results.
Such bias, however, vanishes quickly while observation t, unit amount n, and true strength $\alpha$ increase.
When we increase the time span by including more data from the time dimension, the bias, as well as the RMSE decrease significantly.
Also, when including more cross-section unit n into the simulation, the performance of the estimation improves, as shown by the decreased bias and RMSE values.
An impressive result is that the gap between estimation and true strength will go to zero when we have $\alpha = 1$, the strongest strength we can have.
With the strength approaching unity, both bias and RMSE will converge to zero.
We also present the size of the test in the table.
The size of the test will not vary too much when the strength increases, so as the unit increases.
But we can observe that when observation amounts for each unit increase, in other words, when t increases, the size will shrink dramatically.
The size will become lower than the 0.05 threshold after we extend the t to 240, or empirically speaking, when we included 20 years monthly return data into the estimation.
Notice that, from the equation (\ref{z_indicator}), when $\hat{\alpha} = \alpha = 1$, the nominator becomes zero.
Therefore, the size will collapse to zero in all settings, so we do not report the size for $\hat{\alpha} = \alpha = 1$

%For the two factors scenarios, we obtain similar conclusions in no correlation setting, weak correlation setting, and the strong correlation setting.
For the two factors scenarios, we obtain similar conclusions across all three different correlation settings.
The result of no correlation settings is shown in the table (\ref{table:exp2}), table (\ref{table:exp3}) shows the result when the correlation between two factors is 0.3, and the table (\ref{table:exp4}) presents the result of 0.7 correlation setting.
Same as the single factor scenario, the estimation results improve when increasing either the observations amount t, or the cross-section units amount n.
We also have the same unbiased estimation when true factor strength is unity under all unit-time combinations.
In some cases, even when the factor strength is relatively weak, we can have unbiased estimation if the n and t are big enough. (see table (\ref{table:exp3})).
However, we should also notice that when t > n, the results of the size of the test in two factors setting are performing similar to the single factor result. 
The size will shrink with the observation amount t increasing, and when we have time-series amounts t greater than 240, the size will be smaller than 0.05 threshold in all situations.
However, it is worth notice that in the strong correlation setting, the size of the test is extremely big when the time span is relatively short, and the test size will not improve even we increase the sample size.
Once we increase the t, the size of the test will reduce dramatically, and when we have the thirty year time period, the size of the test are almost all below the 0.05 threshold.

